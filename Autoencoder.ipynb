{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(file_name, spliter=' '):\n",
    "    f = open(file_name)\n",
    "    line = f.readline()\n",
    "    data = []  # 二维数组，[样本总数，720数据]\n",
    "\n",
    "    while line:\n",
    "        trainRead = line.split(spliter)\n",
    "        for i in range(len(trainRead)):\n",
    "            trainRead[i] = float(trainRead[i])\n",
    "        data.append(trainRead)\n",
    "        line = f.readline()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AE Model\n",
    "num_hidden_1 = 256  # 1st layer num features\n",
    "num_hidden_2 = 128  # 2nd layer num features (the latent dim)\n",
    "num_hidden_3 = 128\n",
    "num_input = 720  # img shape: 60*12\n",
    "\n",
    "AE_steps = 30000\n",
    "display_step = AE_steps / 10\n",
    "\n",
    "# combine data\n",
    "sampleDataSet = []  # [7,32,720]\n",
    "sampleDataSet.append(read_file(\"data/imgs_sample_1.txt\"))\n",
    "sampleDataSet.append(read_file(\"data/imgs_sample_2.txt\"))\n",
    "sampleDataSet.append(read_file(\"data/imgs_sample_3.txt\"))\n",
    "sampleDataSet.append(read_file(\"data/imgs_sample_4.txt\"))\n",
    "sampleDataSet.append(read_file(\"data/imgs_sample_5.txt\"))\n",
    "sampleDataSet.append(read_file(\"data/imgs_sample_6.txt\"))\n",
    "sampleDataSet.append(read_file(\"data/imgs_sample_7.txt\"))\n",
    "\n",
    "# FingerPrint\n",
    "FPDataSet = read_file(\"data/ECFPs.txt\", '  ')  # [32,128]\n",
    "\n",
    "# normalize\n",
    "for i in range(len(sampleDataSet)):\n",
    "    sampleDataSet[i] = skl.normalize(sampleDataSet[i], axis=1)\n",
    "# print(sampleDataSet[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDataSetReg:  224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Delete sample only include zero\n",
    "trainAE = []  # data for training\n",
    "for i in range(len(sampleDataSet)):\n",
    "    for j in range(len(sampleDataSet[i])):\n",
    "        if np.sum(sampleDataSet[i][j] != 0):\n",
    "            trainAE.append(sampleDataSet[i][j])  # shape [7, 32, 720] --> [212, 720]\n",
    "# print(\"trainDataSetAE: \", len(trainDataSetAE))  # 212\n",
    "\n",
    "\n",
    "# training of regression\n",
    "trainNN = []\n",
    "for i in range(32):  #\n",
    "    tmpArray = []\n",
    "    for j in range(7):  #\n",
    "        if np.sum(sampleDataSet[j][i] != 0):\n",
    "            tmpArray.append(sampleDataSet[j][i])\n",
    "        trainNN.append(tmpArray)\n",
    "print(\"trainDataSetReg: \", len(trainNN))  # 224, 7, 720\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AutoEncoder model\n",
    "img_input = tf.placeholder('float32', [None, num_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1])),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2])),\n",
    "    # 'encoder_h3': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_3])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1])),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n",
    "    # 'decoder_h3': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2])),\n",
    "    # 'encoder_b3': tf.Variable(tf.random_normal([num_hidden_3])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input])),\n",
    "    # 'decoder_b3': tf.Variable(tf.random_normal([num_input])),\n",
    "}\n",
    "\n",
    "\n",
    "def encoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    # layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['encoder_h3']), biases['encoder_b3']))\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "def decoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    # layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['decoder_h3']), biases['decoder_b3']))\n",
    "    return layer_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_x:  212\n",
      "Step 0: Minibatch Loss: 0.431531\n",
      "Step 3000: Minibatch Loss: 0.085912\n",
      "Step 6000: Minibatch Loss: 0.077975\n",
      "Step 9000: Minibatch Loss: 0.075056\n",
      "Step 12000: Minibatch Loss: 0.021535\n",
      "Step 15000: Minibatch Loss: 0.020171\n",
      "Step 18000: Minibatch Loss: 0.018764\n",
      "Step 21000: Minibatch Loss: 0.018759\n",
      "Step 24000: Minibatch Loss: 0.018757\n",
      "Step 27000: Minibatch Loss: 0.018756\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "encoder_op = encoder(img_input)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "y_pred = decoder_op  # reconstructed image\n",
    "y_true = img_input  # original image\n",
    "\n",
    "learning_rate = 0.01\n",
    "learning_rate2 = learning_rate / 10\n",
    "learning_rate3 = learning_rate2 / 10\n",
    "\n",
    "loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "optimizer2 = tf.train.AdamOptimizer(learning_rate2).minimize(loss)\n",
    "optimizer3 = tf.train.AdamOptimizer(learning_rate3).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training\n",
    "batch_x = trainAE  # 212\n",
    "# print(\"batch_x: \", len(batch_x))\n",
    "\n",
    "_, l = sess.run([optimizer, loss], feed_dict={img_input: batch_x})\n",
    "for j in range(AE_steps):\n",
    "    if j <= AE_steps * 1 / 3:\n",
    "        _, l = sess.run([optimizer, loss], feed_dict={img_input: batch_x})\n",
    "    elif j <= AE_steps * 2 / 3:\n",
    "        _, l = sess.run([optimizer2, loss], feed_dict={img_input: batch_x})\n",
    "    else:\n",
    "        _, l = sess.run([optimizer3, loss], feed_dict={img_input: batch_x})\n",
    "    if j % display_step == 0:\n",
    "        print('Step {0}: Minibatch Loss: {1:<6f}'.format(j, l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-def372e59d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcanvas_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcanvas_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# test performance of AE\n",
    "n = 1\n",
    "m = 20\n",
    "canvas_orig = np.empty((60, 12 * m))\n",
    "canvas_recon = np.empty((60, 12 * m))\n",
    "for i in range(n):\n",
    "    batch_x = trainAE\n",
    "    # Encode and decode the digit image\n",
    "    g = sess.run(decoder_op, feed_dict={img_input: batch_x})\n",
    "\n",
    "    # Display original images\n",
    "    for j in range(m):\n",
    "        # Draw the original digits\n",
    "        # canvas_orig[i * 60:(i + 1) * 60, j * 12:(j + 1) * 12] = batch_x[j].reshape([60, 12])\n",
    "        canvas_orig[0:60, j * 12:(j + 1) * 12] = batch_x[j + 24].reshape([60, 12])\n",
    "    # Display reconstructed images\n",
    "    for j in range(m):\n",
    "        # Draw the reconstructed digits\n",
    "        # canvas_recon[i * 60:(i + 1) * 60, j * 12:(j + 1) * 12] = g[j].reshape([60, 12])\n",
    "        canvas_recon[0:60, j * 12:(j + 1) * 12] = g[j + 24].reshape([60, 12])\n",
    "\n",
    "print(\"Original Images\")\n",
    "plt.figure(figsize=(m, m))\n",
    "plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Reconstructed Images\")\n",
    "plt.figure(figsize=(m, m))\n",
    "plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "\n",
    "result_y = []\n",
    "for i in range(len(trainNN)):\n",
    "    batch_x = trainNN[i]  # [7,720]\n",
    "    batch_y = sess.run(encoder_op, feed_dict={img_input: batch_x})  # [7,128]\n",
    "    result_y.append(batch_y)\n",
    "\n",
    "\n",
    "def random_choose(x):\n",
    "    randInt = np.random.randint(low=0, high=32)\n",
    "    while x == randInt:\n",
    "        randInt = np.random.randint(low=0, high=32)\n",
    "    return randInt\n",
    "\n",
    "\n",
    "# generate neg / pos set\n",
    "negative_ratio = 3\n",
    "batch_data = []  # [None, 256]\n",
    "batch_label = []  # [None, 2]\n",
    "for i in range(len(trainNN)):\n",
    "    data_x = trainNN[i]  # [7,720]，未经过处理的原始数据\n",
    "    data_y = sess.run(encoder_op, feed_dict={img_input: data_x})  # [7,128]，经过AE提取的128维特征\n",
    "\n",
    "    # 产生1个正例，3个反例\n",
    "    data_fpT = []  # [7,128]\n",
    "    data_fpF = []  # [3,7,128]\n",
    "\n",
    "    for j in range(len(data_y)):\n",
    "        data_fpT.append(FPDataSet[j])\n",
    "\n",
    "    for j in range(negative_ratio):\n",
    "        tmp = []\n",
    "        for k in range(len(data_y)):\n",
    "            tmp.append(FPDataSet[random_choose(i)])\n",
    "        data_fpF.append(tmp)\n",
    "\n",
    "    # 对正例和反例进行组装\n",
    "    sample_T = np.append(data_y, data_fpT, axis=1)  # [7,256]\n",
    "    sample_F = np.append(data_y, data_fpF[0], axis=1)  # [21,256]\n",
    "    for j in range(1, negative_ratio):\n",
    "        sample_F = np.append(sample_F, np.append(data_y, data_fpF[j], axis=1), axis=0)\n",
    "\n",
    "    if batch_data == []:\n",
    "        batch_data = np.append(sample_T, sample_F, axis=0)\n",
    "    else:\n",
    "        batch_data = np.append(batch_data, sample_T, axis=0)\n",
    "        batch_data = np.append(batch_data, sample_F, axis=0)\n",
    "    for j in range(len(sample_T)):\n",
    "        batch_label.append([0, 1])  # 正例\n",
    "    for j in range(len(sample_F)):\n",
    "        batch_label.append([1, 0])  # 反例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e236a88a5a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 占位符，基本训练变量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mlabel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "data_size = 256\n",
    "l1_size = 64\n",
    "l2_size = 32\n",
    "l3_size = 8\n",
    "out_size = 2\n",
    "\n",
    "# 占位符，基本训练变量\n",
    "data_input = tf.placeholder(tf.float32, [None, data_size])\n",
    "label_input = tf.placeholder(tf.int64, [None, 2])\n",
    "\n",
    "weightsNN = {\n",
    "    'layer_w1': tf.Variable(tf.random_normal([data_size, l1_size])),\n",
    "    'layer_w2': tf.Variable(tf.random_normal([l1_size, l2_size])),\n",
    "    'layer_w3': tf.Variable(tf.random_normal([l2_size, l3_size])),\n",
    "    'layer_wo': tf.Variable(tf.random_normal([l3_size, out_size])),\n",
    "}\n",
    "\n",
    "biasesNN = {\n",
    "    'layer_b1': tf.Variable(tf.random_normal([l1_size])),\n",
    "    'layer_b2': tf.Variable(tf.random_normal([l2_size])),\n",
    "    'layer_b3': tf.Variable(tf.random_normal([l3_size])),\n",
    "    'layer_bo': tf.Variable(tf.random_normal([out_size])),\n",
    "}\n",
    "\n",
    "\n",
    "# 定义网络结构\n",
    "def network(x):  # 四层结构的全链接网络\n",
    "    layer_1 = tf.add(tf.matmul(x, weightsNN['layer_w1']), biasesNN['layer_b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weightsNN['layer_w2']), biasesNN['layer_b2'])\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weightsNN['layer_w3']), biasesNN['layer_b3'])\n",
    "    layer_o = tf.add(tf.matmul(layer_3, weightsNN['layer_wo']), biasesNN['layer_bo'])\n",
    "    return layer_o\n",
    "\n",
    "\n",
    "y_conv = network(data_input)\n",
    "# 定义损失函数，优化器，正确预测，准确度\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=label_input, logits=y_conv)\n",
    "optimizerNN = tf.train.AdamOptimizer(1e-5).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(label_input, 1), tf.argmax(y_conv, 1))\n",
    "test_out = tf.argmax(y_conv, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# 建立新的session并初始化\n",
    "sessNN = tf.Session()\n",
    "sessNN.run(tf.global_variables_initializer())\n",
    "\n",
    "# 训练网络\n",
    "train_step = 10000\n",
    "print_step = train_step / 20\n",
    "for i in range(train_step):\n",
    "    sessNN.run(optimizerNN, feed_dict={data_input: batch_data, label_input: batch_label})\n",
    "    if i % print_step == 0:\n",
    "        acc = sessNN.run(accuracy, feed_dict={data_input: batch_data, label_input: batch_label})\n",
    "        print(\"step:\", i, \"training accuracy:\", acc)\n",
    "#         print(\"test_out: \", test_out)\n",
    "\n",
    "acc = sessNN.run(accuracy, feed_dict={data_input: batch_data, label_input: batch_label})\n",
    "print(\"Final accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
